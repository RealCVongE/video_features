{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈로 불러다가 Feature값 추출하기 - 4초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03268447 0.1038489  0.06566148 ... 0.43930167 0.45920089 0.04780752]\n",
      " [0.04922621 0.23027417 0.0851275  ... 0.3272149  0.50672305 0.00901898]]\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from models.i3d.extract_i3d import ExtractI3D\n",
    "\n",
    "# 설정을 프로그래밍 방식으로 생성합니다.\n",
    "args = OmegaConf.create({\n",
    "    'feature_type': 'i3d',\n",
    "    'device': 'cuda:0',  # 또는 'cpu'를 사용하시면 됩니다.\n",
    "    'on_extraction': 'ignore',  # 이 설정은 무시될 것입니다.\n",
    "    'output_path': 'ignore',  # 이 설정도 무시됩니다.\n",
    "    'stack_size': 64,  # 이 값들은 예시이며 실제 값으로 대체해야 합니다.\n",
    "    'step_size': 64,\n",
    "    'streams': None,\n",
    "    'flow_type': 'raft',\n",
    "    'extraction_fps': None,\n",
    "    'tmp_path': './tmp/i3d',\n",
    "    'keep_tmp_files': False,\n",
    "    'show_pred': False,\n",
    "    'config': None\n",
    "    # 여기에 args_cli에 필요한 나머지 설정을 추가하십시오.\n",
    "})\n",
    "\n",
    "# Extractor 인스턴스를 만듭니다.\n",
    "extractor = ExtractI3D(args)\n",
    "\n",
    "# 추출 함수를 정의합니다.\n",
    "def extract_features(video_path):\n",
    "    # 영상으로부터 feature를 추출합니다.\n",
    "    features = extractor.extract(video_path)\n",
    "    # RGB features를 가져옵니다.\n",
    "    rgb_features = features['rgb']\n",
    "    return rgb_features\n",
    "\n",
    "# 사용 예시입니다.\n",
    "video_path = '../PreProcess/ori_Training/C_3_12_1_BU_SMB_08-28_16-25-27_CC_RGB_DF2_M1.mp4'  # 여기를 실제 비디오 파일 경로로 바꾸십시오.\n",
    "rgb_features = extract_features(video_path)\n",
    "print(rgb_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 필요한거 추려서 주피터 셀별로 실행하기 - 2초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 번째 셀: 클래스와 필요한 라이브러리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리와 모듈을 임포트합니다.\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from typing import Dict\n",
    "from models.i3d.i3d_src.i3d_net import I3D  # I3D 모델 구현\n",
    "from models._base.base_extractor import BaseExtractor  # 기본 특징 추출기 클래스를 상속\n",
    "from models.transforms import (PILToTensor, ResizeImproved, ScaleTo1_1, TensorCenterCrop, ToFloat, PermuteAndUnsqueeze)\n",
    "from utils.io import reencode_video_with_diff_fps  # 동영상 FPS 조정 유틸리티\n",
    "\n",
    "# I3D 모델을 사용해 RGB 데이터만 추출하는 클래스\n",
    "class ExtractI3D(BaseExtractor):\n",
    "    def __init__(self, args) -> None:\n",
    "        super().__init__(\n",
    "            feature_type=args['feature_type'],\n",
    "            on_extraction=args.get('on_extraction', 'save_numpy'),\n",
    "            tmp_path=args['tmp_path'],\n",
    "            output_path=args['output_path'],\n",
    "            keep_tmp_files=args['keep_tmp_files'],\n",
    "            device=args['device'],\n",
    "        )\n",
    "        self.streams = ['rgb']\n",
    "        self.i3d_classes_num = 400\n",
    "        self.min_side_size = 256\n",
    "        self.central_crop_size = 224\n",
    "        self.extraction_fps = args.get('extraction_fps', None)\n",
    "        self.step_size = args.get('step_size', 64)\n",
    "        self.stack_size = args.get('stack_size', 64)\n",
    "        self.resize_transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToPILImage(),\n",
    "            ResizeImproved(self.min_side_size),\n",
    "            PILToTensor(),\n",
    "            ToFloat(),\n",
    "        ])\n",
    "        self.i3d_transforms = {\n",
    "            'rgb': torchvision.transforms.Compose([\n",
    "                TensorCenterCrop(self.central_crop_size),\n",
    "                ScaleTo1_1(),\n",
    "                PermuteAndUnsqueeze()\n",
    "            ])\n",
    "        }\n",
    "        self.name2module = self.load_model()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract(self, video_path: str) -> Dict[str, np.ndarray]:\n",
    "        if self.extraction_fps is not None:\n",
    "            video_path = reencode_video_with_diff_fps(video_path, self.tmp_path, self.extraction_fps)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        rgb_stack = []\n",
    "        feats_dict = {'rgb': []}\n",
    "\n",
    "        first_frame = True\n",
    "        while cap.isOpened():\n",
    "            frame_exists, rgb = cap.read()\n",
    "\n",
    "            if first_frame:\n",
    "                first_frame = False\n",
    "                if not frame_exists:\n",
    "                    continue\n",
    "\n",
    "            if frame_exists:\n",
    "                rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "                rgb = self.resize_transforms(rgb)\n",
    "                rgb = rgb.unsqueeze(0)\n",
    "                rgb_stack.append(rgb)\n",
    "\n",
    "                if len(rgb_stack) == self.stack_size + 1:\n",
    "                    batch_feats_dict = self.run_on_a_stack(rgb_stack)\n",
    "                    feats_dict['rgb'].extend(batch_feats_dict['rgb'].tolist())\n",
    "                    rgb_stack = rgb_stack[self.step_size:]  # 스텝 사이즈만큼 스택에서 제거\n",
    "            else:\n",
    "                cap.release()\n",
    "                break\n",
    "\n",
    "        if (self.extraction_fps is not None) and (not self.keep_tmp_files):\n",
    "            os.remove(video_path)\n",
    "\n",
    "        feats_dict = {stream: np.array(feats) for stream, feats in feats_dict.items()}\n",
    "        return feats_dict\n",
    "\n",
    "    def run_on_a_stack(self, rgb_stack) -> Dict[str, torch.Tensor]:\n",
    "        models = self.name2module['model']\n",
    "        rgb_stack = torch.cat(rgb_stack[:-1]).to(self.device)  # 마지막 프레임 제거\n",
    "        stream_slice = self.i3d_transforms['rgb'](rgb_stack)\n",
    "        batch_feats_dict = {'rgb': models['rgb'](stream_slice, features=True)}\n",
    "        return batch_feats_dict\n",
    "\n",
    "    def load_model(self) -> Dict[str, torch.nn.Module]:\n",
    "        i3d_weights_paths = {'rgb': './models/i3d/checkpoints/i3d_rgb.pt'}\n",
    "        name2module = {}\n",
    "\n",
    "        i3d_stream_model = I3D(num_classes=self.i3d_classes_num, modality='rgb')\n",
    "        i3d_stream_model.load_state_dict(torch.load(i3d_weights_paths['rgb'], map_location='cpu'))\n",
    "        i3d_stream_model = i3d_stream_model.to(self.device)\n",
    "        i3d_stream_model.eval()\n",
    "        name2module['model'] = {'rgb': i3d_stream_model}\n",
    "\n",
    "        return name2module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두 번째 셀: 설정과 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 설정을 담은 args 딕셔너리를 정의합니다.\n",
    "# 이 설정은 ExtractI3D 클래스를 사용하기 위해 필요한 정보를 포함합니다.\n",
    "# 실제 경로 및 설정은 사용 환경에 맞게 조정해야 합니다.\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "args = OmegaConf.create({\n",
    "    'feature_type': 'i3d',\n",
    "    'device': 'cuda:0',  # 또는 'cpu'를 사용하시면 됩니다.\n",
    "    'on_extraction': 'ignore',  # 이 설정은 무시될 것입니다.\n",
    "    'output_path': 'ignore',  # 이 설정도 무시됩니다.\n",
    "    'stack_size': 64,  # 이 값들은 예시이며 실제 값으로 대체해야 합니다.\n",
    "    'step_size': 64,\n",
    "    'streams': None,\n",
    "    'flow_type': 'raft',\n",
    "    'extraction_fps': None,\n",
    "    'tmp_path': './tmp/i3d',\n",
    "    'keep_tmp_files': False,\n",
    "    'show_pred': False,\n",
    "    'config': None\n",
    "    # 여기에 args_cli에 필요한 나머지 설정을 추가하십시오.\n",
    "})\n",
    "\n",
    "# ExtractI3D 클래스의 인스턴스를 생성합니다.\n",
    "# 위에서 정의한 args 딕셔너리를 생성자에 전달합니다.\n",
    "extractor = ExtractI3D(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세 번째 셀: 동영상 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출된 RGB 특징의 크기: (2, 1024)\n",
      "[[0.03268447 0.1038489  0.06566148 ... 0.43930167 0.45920089 0.04780752]\n",
      " [0.04922621 0.23027417 0.0851275  ... 0.3272149  0.50672305 0.00901898]]\n"
     ]
    }
   ],
   "source": [
    "# 동영상 파일 경로를 지정합니다.\n",
    "# 이 경로는 실제로 특징을 추출하고자 하는 동영상 파일의 위치를 가리킵니다.\n",
    "# 사용자 환경에 맞게 해당 경로를 수정해야 합니다.\n",
    "video_path = '../PreProcess/ori_Training/C_3_12_1_BU_SMB_08-28_16-25-27_CC_RGB_DF2_M1.mp4'\n",
    "\n",
    "# 앞서 생성한 ExtractI3D 인스턴스의 extract 메소드를 호출하여\n",
    "# 지정된 동영상 파일에서 RGB 특징을 추출합니다.\n",
    "# 이 메소드는 추출된 특징들을 사전 형태로 반환합니다.\n",
    "features = extractor.extract(video_path)\n",
    "\n",
    "# 추출된 RGB 특징을 numpy 배열로 받아서 변수에 저장합니다.\n",
    "# 'rgb' 키를 사용하여 사전에서 RGB 특징에 접근할 수 있습니다.\n",
    "rgb_features = features['rgb']\n",
    "\n",
    "# 선택적: 추출된 특징의 크기나 내용을 확인하기 위해 print 함수를 사용할 수 있습니다.\n",
    "print(f\"추출된 RGB 특징의 크기: {rgb_features.shape}\")\n",
    "print(rgb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_features",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
